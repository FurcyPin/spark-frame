from functools import cached_property
from typing import Dict, Generator, List, Optional, cast

from pyspark.sql import DataFrame, Window
from pyspark.sql import functions as f
from pyspark.sql.types import StructType

from spark_frame import transformations
from spark_frame.conf import REPETITION_MARKER
from spark_frame.data_diff.diff_format_options import DiffFormatOptions
from spark_frame.data_diff.diff_per_col import _get_diff_per_col_df_with_cache
from spark_frame.data_diff.diff_stats import DiffStats
from spark_frame.data_diff.export import export_html_diff_report
from spark_frame.data_diff.package import (
    EXISTS_COL_NAME,
    IS_EQUAL_COL_NAME,
    PREDICATES,
    SAMPLE_ID_COL_NAME,
    canonize_col,
)
from spark_frame.data_diff.sample import _get_sample_df_shards_with_cache
from spark_frame.data_diff.schema_diff import DiffPrefix, SchemaDiffResult
from spark_frame.data_diff.special_characters import _restore_special_characters_from_col
from spark_frame.field_utils import get_granularity
from spark_frame.transformations import union_dataframes
from spark_frame.utils import quote, strip_margin


def _unpivot(diff_df: DataFrame) -> DataFrame:
    """Given a diff_df, builds an unpivoted version of it.
    All the values must be cast to STRING to make sure everything fits in the same column.

    Examples:
        >>> from spark_frame.data_diff.diff_result import _get_test_intersection_diff_df
        >>> diff_df = _get_test_intersection_diff_df()
        >>> diff_df.show(truncate=False)
        +------------------------+-------------------------+-------------------------+-------------+
        |id                      |c1                       |c2                       |__SAMPLE_ID__|
        +------------------------+-------------------------+-------------------------+-------------+
        |{1, 1, true, true, true}|{a, d, false, true, true}|{1, 1, true, true, true} |[{"id": 1}]  |
        |{2, 2, true, true, true}|{a, d, false, true, true}|{2, 4, false, true, true}|[{"id": 2}]  |
        +------------------------+-------------------------+-------------------------+-------------+
        <BLANKLINE>
        >>> _unpivot(diff_df).orderBy('column_name', 'diff').show(truncate=False)
        +-----------+--------------------------------------+
        |column_name|diff                                  |
        +-----------+--------------------------------------+
        |c1         |{a, d, false, true, true, [{"id": 1}]}|
        |c1         |{a, d, false, true, true, [{"id": 2}]}|
        |c2         |{1, 1, true, true, true, [{"id": 1}]} |
        |c2         |{2, 4, false, true, true, [{"id": 2}]}|
        |id         |{1, 1, true, true, true, [{"id": 1}]} |
        |id         |{2, 2, true, true, true, [{"id": 2}]} |
        +-----------+--------------------------------------+
        <BLANKLINE>
    """

    diff_df = diff_df.select(
        *[
            f.struct(
                canonize_col(
                    diff_df[quote(field.name) + ".left_value"],
                    cast(StructType, field.dataType).fields[0],
                )
                .cast("STRING")
                .alias("left_value"),
                canonize_col(
                    diff_df[quote(field.name) + ".right_value"],
                    cast(StructType, field.dataType).fields[1],
                )
                .cast("STRING")
                .alias("right_value"),
                diff_df[quote(field.name) + ".is_equal"].alias("is_equal"),
                diff_df[quote(field.name) + ".exists_left"].alias("exists_left"),
                diff_df[quote(field.name) + ".exists_right"].alias("exists_right"),
                diff_df[SAMPLE_ID_COL_NAME].alias("sample_ids"),
            ).alias(field.name)
            for field in diff_df.schema.fields
            if field.name != SAMPLE_ID_COL_NAME
        ],
    )

    unpivoted_df = transformations.unpivot(
        diff_df,
        pivot_columns=[],
        key_alias="column_name",
        value_alias="diff",
    )

    unpivoted_df = unpivoted_df.withColumn("column_name", _restore_special_characters_from_col(f.col("column_name")))
    return unpivoted_df


class DiffResult:
    """Object summarizing the results of a diff between two DataFrames."""

    def __init__(
        self,
        schema_diff_result: SchemaDiffResult,
        diff_df_shards: Dict[str, DataFrame],
        join_cols: List[str],
    ) -> None:
        """Class containing the results of a diff between two DataFrames"""
        self.schema_diff_result: SchemaDiffResult = schema_diff_result
        self.diff_df_shards: Dict[str, DataFrame] = diff_df_shards
        """A dict containing one DataFrame for each level of granularity generated by the diff.

        The DataFrames have the following schema:

        - All fields from join_cols present at this level of granularity
        - For all other fields at this granularity level:
          a Column `col_name: STRUCT<left_value, right_value, is_equal>`
        - A Column `__EXISTS__: STRUCT<left_value, right_value>`
        - A Column `__IS_EQUAL__: BOOLEAN`

        In the simplest cases, there is only one granularity level, called the root level and represented
        by the string `""`. When comparing DataFrames containing arrays of structs, if the user passes a repeated
        field as join_cols (for example `"a!.id"`), then each level of granularity will be generated.
        In the example, there will be two: the root level `""` containing all root-level columns, and the
        level `"a!"` containing all the fields inside the exploded array `a!`; with one row per element inside `a!`.
        """
        self.join_cols: List[str] = join_cols
        """The list of column names to join"""

    @property
    def same_schema(self) -> bool:
        return self.schema_diff_result.same_schema

    @cached_property
    def same_data(self) -> bool:
        return self.top_per_col_state_df.where(
            f.col("state") != f.lit("no_change"),
        ).isEmpty()

    @cached_property
    def total_nb_rows(self) -> int:
        a_join_col = next(col for col in self.join_cols if REPETITION_MARKER not in col)
        return self.top_per_col_state_df.where(
            f.col("column_name") == f.lit(a_join_col),
        ).count()

    @property
    def is_ok(self) -> bool:
        return self.same_schema and self.same_data

    @cached_property
    def diff_stats_shards(self) -> Dict[str, DiffStats]:
        return self._compute_diff_stats_shards()

    @cached_property
    def top_per_col_state_df(self) -> DataFrame:
        def generate() -> Generator[DataFrame, None, None]:
            for key, diff_df in self.diff_df_shards.items():
                keep_cols = [
                    col_name for col_name in self.schema_diff_result.column_names if get_granularity(col_name) == key
                ]
                df = self._compute_top_per_col_state_df(diff_df)
                yield df.where(f.col("column_name").isin(keep_cols))

        return union_dataframes(*generate()).localCheckpoint()

    def get_diff_per_col_df(self, max_nb_rows_per_col_state: int) -> DataFrame:
        """Return a DataFrame that gives for each column and each column state (changed, no_change, only_in_left,
        only_in_right) the total number of occurences and the most frequent occurrences.

        The results returned by this method are cached to avoid unecessary recomputations.

        !!! warning
            The arrays contained in the field `diff` are NOT guaranteed to be sorted,
            and Spark currently does not provide any way to perform a sort_by on an ARRAY<STRUCT>.

        Args:
            max_nb_rows_per_col_state: The maximal size of the arrays in `diff`

        Returns:
            A DataFrame with the following schema:

                root
                 |-- column_number: integer (nullable = true)
                 |-- column_name: string (nullable = true)
                 |-- counts.total: long (nullable = false)
                 |-- counts.changed: long (nullable = false)
                 |-- counts.no_change: long (nullable = false)
                 |-- counts.only_in_left: long (nullable = false)
                 |-- counts.only_in_right: long (nullable = false)
                 |-- diff.changed!.left_value: string (nullable = true)
                 |-- diff.changed!.right_value: string (nullable = true)
                 |-- diff.changed!.nb: long (nullable = false)
                 |-- diff.no_change!.value: string (nullable = true)
                 |-- diff.no_change!.nb: long (nullable = false)
                 |-- diff.only_in_left!.value: string (nullable = true)
                 |-- diff.only_in_left!.nb: long (nullable = false)
                 |-- diff.only_in_right!.value: string (nullable = true)
                 |-- diff.only_in_right!.nb: long (nullable = false)
                <BLANKLINE>

        Examples:
            >>> from spark_frame.data_diff.diff_result import _get_test_diff_result
            >>> diff_result = _get_test_diff_result()
            >>> diff_result.diff_df_shards[''].show(truncate=False)
            +-----------------------------+-----------------------------+-----------------------------+---------------------------------+---------------------------------+-------------+------------+-------------+
            |id                           |c1                           |c2                           |c3                               |c4                               |__EXISTS__   |__IS_EQUAL__|__SAMPLE_ID__|
            +-----------------------------+-----------------------------+-----------------------------+---------------------------------+---------------------------------+-------------+------------+-------------+
            |{1, 1, true, true, true}     |{a, a, true, true, true}     |{1, 1, true, true, true}     |{1, NULL, false, true, false}    |{NULL, 1, false, false, true}    |{true, true} |true        |[{"id": 1}]  |
            |{2, 2, true, true, true}     |{b, b, true, true, true}     |{2, 3, false, true, true}    |{1, NULL, false, true, false}    |{NULL, 1, false, false, true}    |{true, true} |false       |[{"id": 2}]  |
            |{3, 3, true, true, true}     |{b, b, true, true, true}     |{2, 4, false, true, true}    |{2, NULL, false, true, false}    |{NULL, 2, false, false, true}    |{true, true} |false       |[{"id": 3}]  |
            |{4, 4, true, true, true}     |{b, b, true, true, true}     |{2, 4, false, true, true}    |{2, NULL, false, true, false}    |{NULL, 2, false, false, true}    |{true, true} |false       |[{"id": 4}]  |
            |{5, NULL, false, true, false}|{c, NULL, false, true, false}|{3, NULL, false, true, false}|{3, NULL, false, true, false}    |{NULL, NULL, false, false, false}|{true, false}|false       |[{"id": 5}]  |
            |{NULL, 6, false, false, true}|{NULL, f, false, false, true}|{NULL, 3, false, false, true}|{NULL, NULL, false, false, false}|{NULL, 3, false, false, true}    |{false, true}|false       |[{"id": 6}]  |
            +-----------------------------+-----------------------------+-----------------------------+---------------------------------+---------------------------------+-------------+------------+-------------+
            <BLANKLINE>
            >>> diff_result.top_per_col_state_df.show(100)
            +-----------+-------------+----------+-----------+---+-----------+-------+
            |column_name|        state|left_value|right_value| nb| sample_ids|row_num|
            +-----------+-------------+----------+-----------+---+-----------+-------+
            |         c1|    no_change|         b|          b|  3|[{"id": 2}]|      1|
            |         c1|    no_change|         a|          a|  1|[{"id": 1}]|      2|
            |         c1| only_in_left|         c|       NULL|  1|[{"id": 5}]|      1|
            |         c1|only_in_right|      NULL|          f|  1|[{"id": 6}]|      1|
            |         c2|      changed|         2|          4|  2|[{"id": 3}]|      1|
            |         c2|      changed|         2|          3|  1|[{"id": 2}]|      2|
            |         c2|    no_change|         1|          1|  1|[{"id": 1}]|      1|
            |         c2| only_in_left|         3|       NULL|  1|[{"id": 5}]|      1|
            |         c2|only_in_right|      NULL|          3|  1|[{"id": 6}]|      1|
            |         c3| only_in_left|         1|       NULL|  2|[{"id": 1}]|      1|
            |         c3| only_in_left|         2|       NULL|  2|[{"id": 3}]|      2|
            |         c3| only_in_left|         3|       NULL|  1|[{"id": 5}]|      3|
            |         c4|only_in_right|      NULL|          1|  2|[{"id": 1}]|      1|
            |         c4|only_in_right|      NULL|          2|  2|[{"id": 3}]|      2|
            |         c4|only_in_right|      NULL|          3|  1|[{"id": 6}]|      3|
            |         id|    no_change|         1|          1|  1|[{"id": 1}]|      1|
            |         id|    no_change|         2|          2|  1|[{"id": 2}]|      2|
            |         id|    no_change|         3|          3|  1|[{"id": 3}]|      3|
            |         id|    no_change|         4|          4|  1|[{"id": 4}]|      4|
            |         id| only_in_left|         5|       NULL|  1|[{"id": 5}]|      1|
            |         id|only_in_right|      NULL|          6|  1|[{"id": 6}]|      1|
            +-----------+-------------+----------+-----------+---+-----------+-------+
            <BLANKLINE>

            >>> diff_per_col_df = diff_result.get_diff_per_col_df(max_nb_rows_per_col_state=10)
            >>> from spark_frame import nested
            >>> nested.print_schema(diff_per_col_df)
            root
             |-- column_number: integer (nullable = true)
             |-- column_name: string (nullable = true)
             |-- counts.total: long (nullable = false)
             |-- counts.changed: long (nullable = false)
             |-- counts.no_change: long (nullable = false)
             |-- counts.only_in_left: long (nullable = false)
             |-- counts.only_in_right: long (nullable = false)
             |-- diff.changed!.left_value: string (nullable = true)
             |-- diff.changed!.right_value: string (nullable = true)
             |-- diff.changed!.nb: long (nullable = false)
             |-- diff.changed!.sample_ids!: string (nullable = true)
             |-- diff.no_change!.value: string (nullable = true)
             |-- diff.no_change!.nb: long (nullable = false)
             |-- diff.no_change!.sample_ids!: string (nullable = true)
             |-- diff.only_in_left!.value: string (nullable = true)
             |-- diff.only_in_left!.nb: long (nullable = false)
             |-- diff.only_in_left!.sample_ids!: string (nullable = true)
             |-- diff.only_in_right!.value: string (nullable = true)
             |-- diff.only_in_right!.nb: long (nullable = false)
             |-- diff.only_in_right!.sample_ids!: string (nullable = true)
            <BLANKLINE>
            >>> diff_per_col_df.show(truncate=False)
            +-------------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------+
            |column_number|column_name|counts         |diff                                                                                                                                    |
            +-------------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------+
            |0            |id         |{6, 0, 4, 1, 1}|{[], [{1, 1, [{"id": 1}]}, {2, 1, [{"id": 2}]}, {3, 1, [{"id": 3}]}, {4, 1, [{"id": 4}]}], [{5, 1, [{"id": 5}]}], [{6, 1, [{"id": 6}]}]}|
            |1            |c1         |{6, 0, 4, 1, 1}|{[], [{b, 3, [{"id": 2}]}, {a, 1, [{"id": 1}]}], [{c, 1, [{"id": 5}]}], [{f, 1, [{"id": 6}]}]}                                          |
            |2            |c2         |{6, 3, 1, 1, 1}|{[{2, 4, 2, [{"id": 3}]}, {2, 3, 1, [{"id": 2}]}], [{1, 1, [{"id": 1}]}], [{3, 1, [{"id": 5}]}], [{3, 1, [{"id": 6}]}]}                 |
            |3            |c3         |{5, 0, 0, 5, 0}|{[], [], [{1, 2, [{"id": 1}]}, {2, 2, [{"id": 3}]}, {3, 1, [{"id": 5}]}], []}                                                           |
            |4            |c4         |{5, 0, 0, 0, 5}|{[], [], [], [{1, 2, [{"id": 1}]}, {2, 2, [{"id": 3}]}, {3, 1, [{"id": 6}]}]}                                                           |
            +-------------+-----------+---------------+----------------------------------------------------------------------------------------------------------------------------------------+
            <BLANKLINE>
        """  # noqa: E501
        return _get_diff_per_col_df_with_cache(self, max_nb_rows_per_col_state)

    def get_sample_df_shards(self, max_nb_rows_per_col_state: int) -> List[DataFrame]:
        return _get_sample_df_shards_with_cache(self, max_nb_rows_per_col_state)

    def _compute_diff_stats_shard(self, diff_df_shard: DataFrame) -> DiffStats:
        """Given a diff_df and its list of join_cols, return stats about the number of differing or missing rows

        >>> from spark_frame.data_diff.diff_result import _get_test_diff_result
        >>> diff_result = _get_test_diff_result()
        >>> diff_result.diff_df_shards[''].select('__EXISTS__', '__IS_EQUAL__').show()
        +-------------+------------+
        |   __EXISTS__|__IS_EQUAL__|
        +-------------+------------+
        | {true, true}|        true|
        | {true, true}|       false|
        | {true, true}|       false|
        | {true, true}|       false|
        |{true, false}|       false|
        |{false, true}|       false|
        +-------------+------------+
        <BLANKLINE>
        >>> diff_result._compute_diff_stats_shards()['']
        DiffStats(total=6, no_change=1, changed=3, in_left=5, in_right=5, only_in_left=1, only_in_right=1)
        """
        res_df = diff_df_shard.select(
            f.count(f.lit(1)).alias("total"),
            f.sum(
                f.when(
                    PREDICATES.present_in_both & PREDICATES.row_is_equal,
                    f.lit(1),
                ).otherwise(f.lit(0)),
            ).alias(
                "no_change",
            ),
            f.sum(
                f.when(
                    PREDICATES.present_in_both & PREDICATES.row_changed,
                    f.lit(1),
                ).otherwise(f.lit(0)),
            ).alias(
                "changed",
            ),
            f.sum(f.when(PREDICATES.in_left, f.lit(1)).otherwise(f.lit(0))).alias(
                "in_left",
            ),
            f.sum(f.when(PREDICATES.in_right, f.lit(1)).otherwise(f.lit(0))).alias(
                "in_right",
            ),
            f.sum(f.when(PREDICATES.only_in_left, f.lit(1)).otherwise(f.lit(0))).alias(
                "only_in_left",
            ),
            f.sum(f.when(PREDICATES.only_in_right, f.lit(1)).otherwise(f.lit(0))).alias(
                "only_in_right",
            ),
        )
        res = res_df.collect()
        return DiffStats(
            **{k: (v if v is not None else 0) for k, v in res[0].asDict().items()},
        )

    def _compute_diff_stats_shards(self) -> Dict[str, DiffStats]:
        """Given a diff_df and its list of join_cols, return stats about the number of differing or missing rows

        >>> from spark_frame.data_diff.diff_result import _get_test_diff_result
        >>> diff_result = _get_test_diff_result()
        >>> diff_result.diff_df_shards[''].select('__EXISTS__', '__IS_EQUAL__').show()
        +-------------+------------+
        |   __EXISTS__|__IS_EQUAL__|
        +-------------+------------+
        | {true, true}|        true|
        | {true, true}|       false|
        | {true, true}|       false|
        | {true, true}|       false|
        |{true, false}|       false|
        |{false, true}|       false|
        +-------------+------------+
        <BLANKLINE>
        >>> diff_result._compute_diff_stats_shards()['']
        DiffStats(total=6, no_change=1, changed=3, in_left=5, in_right=5, only_in_left=1, only_in_right=1)
        """
        return {
            key: self._compute_diff_stats_shard(diff_df_shard) for key, diff_df_shard in self.diff_df_shards.items()
        }

    def _compute_top_per_col_state_df(self, diff_df: DataFrame) -> DataFrame:
        """Given a diff_df, return a DataFrame with the following properties:

        - One row per tuple (column_name, state, left_value, right_value)
          (where `state` can take the following values: "only_in_left", "only_in_right", "no_change", "changed")
        - A column `nb` that gives the number of occurrence of this specific tuple
        - At most `max_nb_rows_per_col_state` per tuple (column_name, state). Rows with the highest "nb" are kept first.

        Examples:
            >>> from spark_frame.data_diff.diff_result import _get_test_diff_result
            >>> _diff_result = _get_test_diff_result()
            >>> diff_df = _diff_result.diff_df_shards['']
            >>> diff_df.show(truncate=False)
            +-----------------------------+-----------------------------+-----------------------------+---------------------------------+---------------------------------+-------------+------------+-------------+
            |id                           |c1                           |c2                           |c3                               |c4                               |__EXISTS__   |__IS_EQUAL__|__SAMPLE_ID__|
            +-----------------------------+-----------------------------+-----------------------------+---------------------------------+---------------------------------+-------------+------------+-------------+
            |{1, 1, true, true, true}     |{a, a, true, true, true}     |{1, 1, true, true, true}     |{1, NULL, false, true, false}    |{NULL, 1, false, false, true}    |{true, true} |true        |[{"id": 1}]  |
            |{2, 2, true, true, true}     |{b, b, true, true, true}     |{2, 3, false, true, true}    |{1, NULL, false, true, false}    |{NULL, 1, false, false, true}    |{true, true} |false       |[{"id": 2}]  |
            |{3, 3, true, true, true}     |{b, b, true, true, true}     |{2, 4, false, true, true}    |{2, NULL, false, true, false}    |{NULL, 2, false, false, true}    |{true, true} |false       |[{"id": 3}]  |
            |{4, 4, true, true, true}     |{b, b, true, true, true}     |{2, 4, false, true, true}    |{2, NULL, false, true, false}    |{NULL, 2, false, false, true}    |{true, true} |false       |[{"id": 4}]  |
            |{5, NULL, false, true, false}|{c, NULL, false, true, false}|{3, NULL, false, true, false}|{3, NULL, false, true, false}    |{NULL, NULL, false, false, false}|{true, false}|false       |[{"id": 5}]  |
            |{NULL, 6, false, false, true}|{NULL, f, false, false, true}|{NULL, 3, false, false, true}|{NULL, NULL, false, false, false}|{NULL, 3, false, false, true}    |{false, true}|false       |[{"id": 6}]  |
            +-----------------------------+-----------------------------+-----------------------------+---------------------------------+---------------------------------+-------------+------------+-------------+
            <BLANKLINE>
            >>> (_diff_result._compute_top_per_col_state_df(diff_df)
            ...  .orderBy("column_name", "state", "left_value", "right_value")
            ... ).show(100)
            +-----------+-------------+----------+-----------+---+-----------+-------+
            |column_name|        state|left_value|right_value| nb| sample_ids|row_num|
            +-----------+-------------+----------+-----------+---+-----------+-------+
            |         c1|    no_change|         a|          a|  1|[{"id": 1}]|      2|
            |         c1|    no_change|         b|          b|  3|[{"id": 2}]|      1|
            |         c1| only_in_left|         c|       NULL|  1|[{"id": 5}]|      1|
            |         c1|only_in_right|      NULL|          f|  1|[{"id": 6}]|      1|
            |         c2|      changed|         2|          3|  1|[{"id": 2}]|      2|
            |         c2|      changed|         2|          4|  2|[{"id": 3}]|      1|
            |         c2|    no_change|         1|          1|  1|[{"id": 1}]|      1|
            |         c2| only_in_left|         3|       NULL|  1|[{"id": 5}]|      1|
            |         c2|only_in_right|      NULL|          3|  1|[{"id": 6}]|      1|
            |         c3| only_in_left|         1|       NULL|  2|[{"id": 1}]|      1|
            |         c3| only_in_left|         2|       NULL|  2|[{"id": 3}]|      2|
            |         c3| only_in_left|         3|       NULL|  1|[{"id": 5}]|      3|
            |         c4|only_in_right|      NULL|          1|  2|[{"id": 1}]|      1|
            |         c4|only_in_right|      NULL|          2|  2|[{"id": 3}]|      2|
            |         c4|only_in_right|      NULL|          3|  1|[{"id": 6}]|      3|
            |         id|    no_change|         1|          1|  1|[{"id": 1}]|      1|
            |         id|    no_change|         2|          2|  1|[{"id": 2}]|      2|
            |         id|    no_change|         3|          3|  1|[{"id": 3}]|      3|
            |         id|    no_change|         4|          4|  1|[{"id": 4}]|      4|
            |         id| only_in_left|         5|       NULL|  1|[{"id": 5}]|      1|
            |         id|only_in_right|      NULL|          6|  1|[{"id": 6}]|      1|
            +-----------+-------------+----------+-----------+---+-----------+-------+
            <BLANKLINE>
        """  # noqa: E501
        diff_df = diff_df.drop(IS_EQUAL_COL_NAME, EXISTS_COL_NAME)
        unpivoted_diff_df = _unpivot(diff_df)

        only_in_left = f.col("diff")["exists_left"] & ~f.col("diff")["exists_right"]
        only_in_right = ~f.col("diff")["exists_left"] & f.col("diff")["exists_right"]
        exists_in_left_or_right = f.col("diff")["exists_left"] | f.col("diff")["exists_right"]

        df_1 = unpivoted_diff_df.select(
            "column_name",
            f.when(only_in_left, f.lit("only_in_left"))
            .when(only_in_right, f.lit("only_in_right"))
            .when(f.col("diff")["is_equal"], f.lit("no_change"))
            .otherwise(f.lit("changed"))
            .alias("state"),
            "diff.left_value",
            "diff.right_value",
            "diff.sample_ids",
        ).where(exists_in_left_or_right)
        window = Window.partitionBy("column_name", "state").orderBy(
            f.col("nb").desc(),
            f.col("left_value"),
            f.col("right_value"),
        )
        df_2 = (
            df_1.groupBy("column_name", "state", "left_value", "right_value")
            .agg(f.count(f.lit(1)).alias("nb"), f.first("sample_ids").alias("sample_ids"))
            .withColumn("row_num", f.row_number().over(window))
        )
        return df_2

    def display(
        self,
        show_examples: bool = False,
        diff_format_options: Optional[DiffFormatOptions] = None,
    ) -> None:
        """Print a summary of the results in the standard output

        Args:
            show_examples: If true, display example of rows for each type of change
            diff_format_options: Formatting options

        Examples:
            See [spark_frame.data_diff.compare_dataframes][spark_frame.data_diff.compare_dataframes] for more examples.

            >>> from spark_frame.data_diff.diff_result import _get_test_diff_result
            >>> diff_result = _get_test_diff_result()
            >>> diff_result.display()
            Schema has changed:
            @@ -1,6 +1,6 @@
                 id INT
                 c1 STRING
                 c2 STRING
            -    c3 STRING
            +    c4 STRING
            <BLANKLINE>
            WARNING: columns that do not match both sides will be ignored
            <BLANKLINE>
            diff NOT ok
            <BLANKLINE>
            Row count ok: 5 rows
            <BLANKLINE>
            1 (16.67%) rows are identical
            3 (50.0%) rows have changed
            1 (16.67%) rows are only in 'left'
            1 (16.67%) rows are only in 'right
            <BLANKLINE>
            Found the following changes:
            +-----------+-------------+----------+-----------+--------------+
            |column_name|total_nb_diff|left_value|right_value|nb_differences|
            +-----------+-------------+----------+-----------+--------------+
            |c2         |3            |2         |4          |2             |
            |c2         |3            |2         |3          |1             |
            +-----------+-------------+----------+-----------+--------------+
            <BLANKLINE>
            1 rows were only found in 'left' :
            Most frequent values in 'left' for each column :
            +-----------+-----+---+
            |column_name|value|nb |
            +-----------+-----+---+
            |id         |5    |1  |
            |c1         |c    |1  |
            |c2         |3    |1  |
            |c3         |1    |2  |
            |c3         |2    |2  |
            |c3         |3    |1  |
            +-----------+-----+---+
            <BLANKLINE>
            1 rows were only found in 'right' :
            Most frequent values in 'right' for each column :
            +-----------+-----+---+
            |column_name|value|nb |
            +-----------+-----+---+
            |id         |6    |1  |
            |c1         |f    |1  |
            |c2         |3    |1  |
            |c4         |1    |2  |
            |c4         |2    |2  |
            |c4         |3    |1  |
            +-----------+-----+---+
            <BLANKLINE>
        """
        if diff_format_options is None:
            diff_format_options = DiffFormatOptions()
        from spark_frame.data_diff.diff_result_analyzer import DiffResultAnalyzer

        self.schema_diff_result.display()
        analyzer = DiffResultAnalyzer(diff_format_options)
        analyzer.display_diff_results(self, show_examples)

    def export_to_html(
        self,
        title: Optional[str] = None,
        output_file_path: str = "diff_report.html",
        encoding: str = "utf8",
        diff_format_options: Optional[DiffFormatOptions] = None,
    ) -> None:
        """Generate an HTML report of this diff result.

        This generates an HTML report file at the specified `output_file_path` URI location.

        The report file can be opened directly with a web browser, even without any internet connection.

        !!! info
            This method uses Spark's FileSystem API to write the report.
            This means that `output_file_path` behaves the same way as the path argument in `df.write.save(path)`:

            - It can be a fully qualified URI pointing to a location on a remote filesystem
              (e.g. "hdfs://...", "s3://...", etc.), provided that Spark is configured to access it
            - If a relative path with no scheme is specified (e.g. `output_file_path="diff_report.html"`), it will
              write on Spark's default's output location. For example:
                - when running locally, it will be the process current working directory.
                - when running on Hadoop, it will be the user's home directory on HDFS.
                - when running on the cloud (EMR, Dataproc, Azure Synapse, Databricks), it should write on the
                  default remote storage linked to the cluster.

        Args:
            title: The title of the report
            encoding: Encoding used when writing the html report
            output_file_path: URI of the file to write to.
            diff_format_options: Formatting options

        Examples:
            >>> from spark_frame.data_diff.diff_result import _get_test_diff_result
            >>> diff_result = _get_test_diff_result()
            >>> diff_result.export_to_html(output_file_path="test_working_dir/diff_result_export_to_html_example.html")
            Report exported as test_working_dir/diff_result_export_to_html_example.html

            [Check out the exported report here](../diff_reports/diff_result_export_to_html_example.html)
        """
        if diff_format_options is None:
            diff_format_options = DiffFormatOptions()
        from spark_frame.data_diff.diff_result_analyzer import DiffResultAnalyzer

        analyzer = DiffResultAnalyzer(diff_format_options)
        diff_result_summary = analyzer.get_diff_result_summary(self)
        export_html_diff_report(
            diff_result_summary,
            title=title,
            output_file_path=output_file_path,
            encoding=encoding,
        )


def _get_test_diff_result() -> "DiffResult":
    from spark_frame.data_diff.package import _get_test_diff_df

    _diff_df = _get_test_diff_df()
    diff_str = strip_margin(
        """
    |@@ -1,6 +1,6 @@
    |     id INT
    |     c1 STRING
    |     c2 STRING
    |-    c3 STRING
    |+    c4 STRING
    |""",
    )

    column_names_diff = {
        "id": DiffPrefix.UNCHANGED,
        "c1": DiffPrefix.UNCHANGED,
        "c2": DiffPrefix.UNCHANGED,
        "c3": DiffPrefix.REMOVED,
        "c4": DiffPrefix.ADDED,
    }
    schema_diff_result = SchemaDiffResult(
        same_schema=False,
        diff_str=diff_str,
        nb_cols=0,
        column_names_diff=column_names_diff,
    )
    return DiffResult(
        schema_diff_result,
        diff_df_shards={"": _diff_df},
        join_cols=["id"],
    )


def _get_test_intersection_diff_df() -> DataFrame:
    from pyspark.sql import SparkSession

    spark = SparkSession.builder.appName("doctest").getOrCreate()
    diff_df = spark.sql(
        """
        SELECT INLINE(ARRAY(
            STRUCT(
                STRUCT(1 as left_value, 1 as right_value, True as is_equal,
                       True as exists_left, True as exists_right
                ) as id,
                STRUCT("a" as left_value, "d" as right_value, False as is_equal,
                       True as exists_left, True as exists_right
                ) as c1,
                STRUCT(1 as left_value, 1 as right_value, True as is_equal,
                       True as exists_left, True as exists_right
                ) as c2,
                ARRAY('{"id": 1}') as __SAMPLE_ID__
            ),
            STRUCT(
                STRUCT(2 as left_value, 2 as right_value, True as is_equal,
                       True as exists_left, True as exists_right
                ) as id,
                STRUCT("a" as left_value, "d" as right_value, False as is_equal,
                       True as exists_left, True as exists_right
                ) as c1,
                STRUCT(2 as left_value, 4 as right_value, False as is_equal,
                       True as exists_left, True as exists_right
                ) as c2,
                ARRAY('{"id": 2}') as __SAMPLE_ID__
            )
        ))
    """,
    )
    return diff_df
